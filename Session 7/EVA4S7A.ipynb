{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "EVA4S7A.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bikash-bhoi/eva4/blob/master/Session%207/EVA4S7A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVbdg0z4poCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPogbueepoCh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Training a Classifier\n",
        "=====================\n",
        "\n",
        "This is it. You have seen how to define neural networks, compute loss and make\n",
        "updates to the weights of the network.\n",
        "\n",
        "Now you might be thinking,\n",
        "\n",
        "What about data?\n",
        "----------------\n",
        "\n",
        "Generally, when you have to deal with image, text, audio or video data,\n",
        "you can use standard python packages that load data into a numpy array.\n",
        "Then you can convert this array into a ``torch.*Tensor``.\n",
        "\n",
        "-  For images, packages such as Pillow, OpenCV are useful\n",
        "-  For audio, packages such as scipy and librosa\n",
        "-  For text, either raw Python or Cython based loading, or NLTK and\n",
        "   SpaCy are useful\n",
        "\n",
        "Specifically for vision, we have created a package called\n",
        "``torchvision``, that has data loaders for common datasets such as\n",
        "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
        "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
        "\n",
        "This provides a huge convenience and avoids writing boilerplate code.\n",
        "\n",
        "For this tutorial, we will use the CIFAR10 dataset.\n",
        "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
        "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
        "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        ".. figure:: /_static/img/cifar10.png\n",
        "   :alt: cifar10\n",
        "\n",
        "   cifar10\n",
        "\n",
        "\n",
        "Training an image classifier\n",
        "----------------------------\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Convolution Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "1. Loading and normalizing CIFAR10\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yVpodAMpoCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kjt4e2TpoCk",
        "colab_type": "text"
      },
      "source": [
        "The output of torchvision datasets are PILImage images of range [0, 1].\n",
        "We transform them to Tensors of normalized range [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Tjigo2poCl",
        "colab_type": "code",
        "outputId": "e1586ad7-bbab-4d9a-b893-52e6d96f1a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cj433rtpoCn",
        "colab_type": "text"
      },
      "source": [
        "Let us show some of the training images, for fun.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daA7bADhpoCo",
        "colab_type": "code",
        "outputId": "486654dc-cdd1-430e-be01-6c0413d9d4a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " bird plane   car  bird\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28OpHA_LpoCq",
        "colab_type": "text"
      },
      "source": [
        "2. Define a Convolution Neural Network\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Copy the neural network from the Neural Networks section before and modify it to\n",
        "take 3-channel images (instead of 1-channel images as it was defined).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jjLwLLQpoCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "557c7895-1fa5-4391-e368-94b1c6e639b1"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_block1= nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3,3), bias=False, padding=1, padding_mode='same'), #32 -> 32, 3 (in->out, RF)\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), bias=False, padding=1), #32 -> 32, 5\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(), \n",
        "        )\n",
        "        self.shortcut1 = nn.Sequential(\n",
        "                nn.Conv2d(3, 128, kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(128)\n",
        "        )\n",
        "        self.trans_block1= nn.Sequential(\n",
        "            nn.MaxPool2d(2,2),#32 -> 16, 6\n",
        "            nn.Conv2d(128, 64, kernel_size=1, stride=1, bias=False)\n",
        "\n",
        "        )\n",
        "        self.conv_block2= nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), bias=False, padding=1), #16 -> 16, 10\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            #Depthwise separable convolution\n",
        "            nn.Conv2d(128, 128, kernel_size=(3,3), padding=1, groups=128) , #16->16, 14\n",
        "            #pointwise convolution\n",
        "            nn.Conv2d(128, 256, kernel_size=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.shortcut2 = nn.Sequential(\n",
        "                nn.Conv2d(64, 256, kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(256)\n",
        "        )\n",
        "        self.trans_block2= nn.Sequential(\n",
        "            nn.MaxPool2d(2,2),#32 -> 16->8, 16\n",
        "            nn.Conv2d(in_channels=256, out_channels=32, kernel_size=(1,1))\n",
        "        )\n",
        "        self.conv_block3= nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), bias=False, padding=1), #8 -> 8, 24\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=(3,3), padding=1) , #8->8, 32\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.shortcut3 = nn.Sequential(\n",
        "                nn.Conv2d(32, 128, kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(128)\n",
        "        )\n",
        "        self.conv_block4 = nn.Sequential(\n",
        "            #Dialated convolution\n",
        "            nn.Conv2d(128, 512, kernel_size=(3,3), padding=1, bias=False,dilation=2) #8->6, 40\n",
        "        )\n",
        "        self.final_block= nn.Sequential(\n",
        "            #GAP\n",
        "            nn.AvgPool2d(kernel_size=6),  #6->1, 60\n",
        "            nn.Conv2d(in_channels=512, out_channels=10, kernel_size=(1,1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1= self.conv_block1(x)\n",
        "        out1 += self.shortcut1(x)    #add shortcut ResNet like\n",
        "        out1= self.trans_block1(out1)\n",
        "        out2= self.conv_block2(out1)\n",
        "        out2 += self.shortcut2(out1) #add shortcut ResNet like\n",
        "        out2= self.trans_block2(out2)\n",
        "        out3= self.conv_block3(out2)\n",
        "        out3 += self.shortcut3(out2) #add shortcut ResNet like\n",
        "        x = self.conv_block4(out3)\n",
        "        x= self.final_block(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "net = Net().to(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udtJkNk28zG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "outputId": "8af51e24-68d0-489c-bd41-1ef162a0e680"
      },
      "source": [
        "#!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "net = Net().to(device)\n",
        "summary(net, input_size=(3, 32, 32))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4          [-1, 128, 32, 32]          73,728\n",
            "       BatchNorm2d-5          [-1, 128, 32, 32]             256\n",
            "              ReLU-6          [-1, 128, 32, 32]               0\n",
            "            Conv2d-7          [-1, 128, 32, 32]             384\n",
            "       BatchNorm2d-8          [-1, 128, 32, 32]             256\n",
            "         MaxPool2d-9          [-1, 128, 16, 16]               0\n",
            "           Conv2d-10           [-1, 64, 16, 16]           8,192\n",
            "           Conv2d-11          [-1, 128, 16, 16]          73,728\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "           Conv2d-14          [-1, 128, 16, 16]           1,280\n",
            "           Conv2d-15          [-1, 256, 16, 16]          33,024\n",
            "      BatchNorm2d-16          [-1, 256, 16, 16]             512\n",
            "             ReLU-17          [-1, 256, 16, 16]               0\n",
            "           Conv2d-18          [-1, 256, 16, 16]          16,384\n",
            "      BatchNorm2d-19          [-1, 256, 16, 16]             512\n",
            "        MaxPool2d-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21             [-1, 32, 8, 8]           8,224\n",
            "           Conv2d-22             [-1, 64, 8, 8]          18,432\n",
            "      BatchNorm2d-23             [-1, 64, 8, 8]             128\n",
            "             ReLU-24             [-1, 64, 8, 8]               0\n",
            "           Conv2d-25            [-1, 128, 8, 8]          73,856\n",
            "      BatchNorm2d-26            [-1, 128, 8, 8]             256\n",
            "             ReLU-27            [-1, 128, 8, 8]               0\n",
            "           Conv2d-28            [-1, 128, 8, 8]           4,096\n",
            "      BatchNorm2d-29            [-1, 128, 8, 8]             256\n",
            "           Conv2d-30            [-1, 512, 6, 6]         589,824\n",
            "        AvgPool2d-31            [-1, 512, 1, 1]               0\n",
            "           Conv2d-32             [-1, 10, 1, 1]           5,130\n",
            "================================================================\n",
            "Total params: 910,570\n",
            "Trainable params: 910,570\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 11.07\n",
            "Params size (MB): 3.47\n",
            "Estimated Total Size (MB): 14.55\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wdw2NNCUpoCu",
        "colab_type": "text"
      },
      "source": [
        "3. Define a Loss function and optimizer\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-odOrhdpoC2",
        "colab_type": "text"
      },
      "source": [
        "4. Train the network\n",
        "^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "This is when things start to get interesting.\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLrvL_fHpoC5",
        "colab_type": "text"
      },
      "source": [
        "5. Test the network on the test data\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display an image from the test set to get familiar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8OTHZEApoC_",
        "colab_type": "text"
      },
      "source": [
        "The outputs are energies for the 10 classes.\n",
        "Higher the energy for a class, the more the network\n",
        "thinks that the image is of the particular class.\n",
        "So, let's get the index of the highest energy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ4-5CESpoDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "3050174a-48b1-4741-95cf-9ee8c212cf1f"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 69 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kupt9vTGVkQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses_1 = []\n",
        "train_acc = []\n",
        "test_acc_1 = []\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    \n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "  train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses_1.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc_1.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu-aNAfcVsCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "57a1d387-f8b9-4f67-ba69-6a276196f022"
      },
      "source": [
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "scheduler = OneCycleLR(optimizer,max_lr=0.2,total_steps=20)\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    print(f'Epoch: {epoch} Learning_Rate {scheduler.get_lr()}')\n",
        "    train(model, device, trainloader, optimizer, epoch)\n",
        "    test(model, device, testloader)\n",
        "    scheduler.step()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Learning_Rate [0.008000000000000007]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "Loss=0.8202915191650391 Batch_id=12499 Accuracy=44.22: 100%|██████████| 12500/12500 [02:19<00:00, 89.74it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.1671, Accuracy: 5883/10000 (58.83%)\n",
            "\n",
            "Epoch: 2 Learning_Rate [0.026334368540005065]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=2.1871044635772705 Batch_id=12499 Accuracy=37.15: 100%|██████████| 12500/12500 [02:23<00:00, 86.88it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 3.0926, Accuracy: 2758/10000 (27.58%)\n",
            "\n",
            "Epoch: 3 Learning_Rate [0.07433436854000505]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=nan Batch_id=12499 Accuracy=10.00: 100%|██████████| 12500/12500 [02:25<00:00, 85.64it/s]\n",
            "  0%|          | 0/12500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: nan, Accuracy: 1000/10000 (10.00%)\n",
            "\n",
            "Epoch: 4 Learning_Rate [0.13366563145999494]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=nan Batch_id=8868 Accuracy=10.00:  71%|███████   | 8861/12500 [01:43<00:42, 85.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f671ceb8df37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch} Learning_Rate {scheduler.get_lr()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-1cea695dd28c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# get samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mWELCOME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend_bytes\u001b[0;34m(self, buf, offset, size)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"buffer length < offset + size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send_bytes\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;31m# Also note we want to avoid sending a 0-length buffer separately,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;31m# to avoid \"broken pipe\" errors if the other end closed the pipe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, buf, write)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0mremaining\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ff46066f-803e-40c6-f474-82d45e0b1ec4",
        "id": "cW0IaJYaIroo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of plane : 62 %\n",
            "Accuracy of   car : 47 %\n",
            "Accuracy of  bird : 59 %\n",
            "Accuracy of   cat : 25 %\n",
            "Accuracy of  deer : 47 %\n",
            "Accuracy of   dog : 60 %\n",
            "Accuracy of  frog : 58 %\n",
            "Accuracy of horse : 61 %\n",
            "Accuracy of  ship : 64 %\n",
            "Accuracy of truck : 61 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDdwPBl8poDF",
        "colab_type": "text"
      },
      "source": [
        "That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
        "a class out of 10 classes).\n",
        "Seems like the network learnt something.\n",
        "\n",
        "Hmmm, what are the classes that performed well, and the classes that did\n",
        "not perform well:\n",
        "\n"
      ]
    }
  ]
}