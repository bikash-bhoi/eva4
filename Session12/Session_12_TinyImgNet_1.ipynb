{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session_12_TinyImgNet_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bikash-bhoi/eva4/blob/master/Session12/Session_12_TinyImgNet_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwcC29-mHU7H",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g7ee78QSLcf",
        "colab_type": "code",
        "outputId": "71f1a554-5627-4594-ec11-e4f7147494b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##Clone Github Directory to import packages\n",
        "%%bash\n",
        "mkdir temp\n",
        "git clone https://github.com/bikash-bhoi/eva4.git temp\n",
        "if [ ! -d ./models ]; then\n",
        "    mkdir models\n",
        "fi\n",
        "if [ ! -d ./utils ]; then\n",
        "    mkdir utils\n",
        "fi\n",
        "cp -r temp/models/* ./models\n",
        "cp -r temp/utils/* ./utils\n",
        "rm -rf temp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'temp'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5jmWLvznBDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install pytorch-gradcam\n",
        "!pip install albumentations\n",
        "!pip install livelossplot\n",
        "#!pip install --no-cache-dir git+https://github.com/NVIDIA/apex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAMhoRfM-4nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from utils.download_load import download_load\n",
        "#from utils.display_imgs import display_imgs\n",
        "from utils.train_test import train , test, predict, get_misclassified\n",
        "from utils.disp_summary import disp_summary\n",
        "#from utils.gradcam import grad_cam, gradcam_plot\n",
        "from models.resnet import ResNet18,ResNet\n",
        "from utils.range_test import lr_range_test\n",
        "from utils.train_model import train_model\n",
        "#from utils.zig_zag_plot import zigzag_plot\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchsummary\n",
        "from torchsummary import summary\n",
        "import torch,os\n",
        "import torch.utils.data as data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj2uhhjFKcM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/tiny-imagenet-200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI_r1Qto8Tc_",
        "colab_type": "code",
        "outputId": "840c731c-35cd-4642-ea65-8ca1702b3ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "#!rm -rf /content/tiny-imagenet-200\n",
        "!unzip -q \"/content/gdrive/My Drive/tiny-imagenet-200.zip\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lv_KpvNFkRf",
        "colab_type": "code",
        "outputId": "71d854ec-1c0c-4235-965f-bad8c9129094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from shutil import move\n",
        "data_dir = '/content/tiny-imagenet-200/'\n",
        "train_dir = data_dir+'train/'\n",
        "val_dir = data_dir+'val/'\n",
        "val_annot = val_dir+'val_annotations.txt'\n",
        "\n",
        "print('Pre')\n",
        "print(len(os.listdir(val_dir+'images/')))\n",
        "print(sum(1 for line in open(val_annot)))\n",
        "\n",
        "\n",
        "for tp in os.listdir(train_dir):\n",
        "    \n",
        "    for i in range(385,500):\n",
        "        img=train_dir+tp+'/'+'images/'+tp+'_'+str(i)+'.JPEG'\n",
        "        # Move 113 images to Val dataset\n",
        "        move(img,val_dir+'images/')\n",
        "    #Move annotation txt to val annotation\n",
        "    train_annot = train_dir+tp+'/'+tp+'_boxes.txt'\n",
        "    \n",
        "    #Read Train annotaions\n",
        "    with open(train_annot) as f1:lines = f1.readlines()\n",
        "\n",
        "    #Append last 115 Train annotations to val annotation\n",
        "    with open(val_annot, 'a') as f2: f2.writelines(lines[385:])\n",
        "\n",
        "    #Overwrite Train annotation with first 385 Lines\n",
        "    with open(train_annot, 'w') as f3: f3.writelines(lines[:385])\n",
        "\n",
        "print('Post')\n",
        "print(len(os.listdir(val_dir+'images/')))\n",
        "print(sum(1 for line in open(val_annot)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pre\n",
            "10000\n",
            "10000\n",
            "Post\n",
            "33000\n",
            "33000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F5_WAaIQ05S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/tiny-imagenet-200/'\n",
        "num_workers = {'train' : 100,'val'   : 0,'test'  : 0}\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
        "    ])\n",
        "}\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) \n",
        "                  for x in ['train', 'val','test']}\n",
        "dataloaders = {x: data.DataLoader(image_datasets[x], batch_size=512, shuffle=True, num_workers=num_workers[x])\n",
        "                  for x in ['train', 'val', 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siA2JN5dTwoy",
        "colab_type": "code",
        "outputId": "6bd3bc00-560c-4be6-c6ee-5981b545d7d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset_sizes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': 10000, 'train': 77000, 'val': 33000}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ays4k29NzQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "model = models.resnet18()\n",
        "#Finetune Final few layers to adjust for tiny imagenet input\n",
        "model.conv1 = nn.Conv2d(3,64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)\n",
        "model.maxpool = nn.Sequential()\n",
        "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "model.fc.out_features = 200\n",
        "\n",
        "#model=ResNet18(200)\n",
        "#model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "use_cuda= torch.cuda.is_available()\n",
        "device=torch.device('cuda' if use_cuda else 'cpu')\n",
        "model=model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f6-gJxyOM7t",
        "colab_type": "code",
        "outputId": "d4a257ca-1a48-4cd5-b5f7-43a4f7c664ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "disp_summary(model,[3,64,64])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 64]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
            "              ReLU-3           [-1, 64, 64, 64]               0\n",
            "            Conv2d-4           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-5           [-1, 64, 64, 64]             128\n",
            "              ReLU-6           [-1, 64, 64, 64]               0\n",
            "            Conv2d-7           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-8           [-1, 64, 64, 64]             128\n",
            "              ReLU-9           [-1, 64, 64, 64]               0\n",
            "       BasicBlock-10           [-1, 64, 64, 64]               0\n",
            "           Conv2d-11           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-12           [-1, 64, 64, 64]             128\n",
            "             ReLU-13           [-1, 64, 64, 64]               0\n",
            "           Conv2d-14           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-15           [-1, 64, 64, 64]             128\n",
            "             ReLU-16           [-1, 64, 64, 64]               0\n",
            "       BasicBlock-17           [-1, 64, 64, 64]               0\n",
            "           Conv2d-18          [-1, 128, 32, 32]          73,728\n",
            "      BatchNorm2d-19          [-1, 128, 32, 32]             256\n",
            "             ReLU-20          [-1, 128, 32, 32]               0\n",
            "           Conv2d-21          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-22          [-1, 128, 32, 32]             256\n",
            "           Conv2d-23          [-1, 128, 32, 32]           8,192\n",
            "      BatchNorm2d-24          [-1, 128, 32, 32]             256\n",
            "             ReLU-25          [-1, 128, 32, 32]               0\n",
            "       BasicBlock-26          [-1, 128, 32, 32]               0\n",
            "           Conv2d-27          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-28          [-1, 128, 32, 32]             256\n",
            "             ReLU-29          [-1, 128, 32, 32]               0\n",
            "           Conv2d-30          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-31          [-1, 128, 32, 32]             256\n",
            "             ReLU-32          [-1, 128, 32, 32]               0\n",
            "       BasicBlock-33          [-1, 128, 32, 32]               0\n",
            "           Conv2d-34          [-1, 256, 16, 16]         294,912\n",
            "      BatchNorm2d-35          [-1, 256, 16, 16]             512\n",
            "             ReLU-36          [-1, 256, 16, 16]               0\n",
            "           Conv2d-37          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-38          [-1, 256, 16, 16]             512\n",
            "           Conv2d-39          [-1, 256, 16, 16]          32,768\n",
            "      BatchNorm2d-40          [-1, 256, 16, 16]             512\n",
            "             ReLU-41          [-1, 256, 16, 16]               0\n",
            "       BasicBlock-42          [-1, 256, 16, 16]               0\n",
            "           Conv2d-43          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-44          [-1, 256, 16, 16]             512\n",
            "             ReLU-45          [-1, 256, 16, 16]               0\n",
            "           Conv2d-46          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-47          [-1, 256, 16, 16]             512\n",
            "             ReLU-48          [-1, 256, 16, 16]               0\n",
            "       BasicBlock-49          [-1, 256, 16, 16]               0\n",
            "           Conv2d-50            [-1, 512, 8, 8]       1,179,648\n",
            "      BatchNorm2d-51            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-52            [-1, 512, 8, 8]               0\n",
            "           Conv2d-53            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-54            [-1, 512, 8, 8]           1,024\n",
            "           Conv2d-55            [-1, 512, 8, 8]         131,072\n",
            "      BatchNorm2d-56            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-57            [-1, 512, 8, 8]               0\n",
            "       BasicBlock-58            [-1, 512, 8, 8]               0\n",
            "           Conv2d-59            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-60            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-61            [-1, 512, 8, 8]               0\n",
            "           Conv2d-62            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-63            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-64            [-1, 512, 8, 8]               0\n",
            "       BasicBlock-65            [-1, 512, 8, 8]               0\n",
            "AdaptiveAvgPool2d-66            [-1, 512, 1, 1]               0\n",
            "           Linear-67                 [-1, 1000]         513,000\n",
            "================================================================\n",
            "Total params: 11,681,832\n",
            "Trainable params: 11,681,832\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 62.01\n",
            "Params size (MB): 44.56\n",
            "Estimated Total Size (MB): 106.62\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CZTHNLGLGh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrs = [j*(10**i) for i in range(-3,-1) for j in range(1,11)]\n",
        "lr_range_test(lrs,model,device,train_loader, test_loader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ7c7UTxOPJn",
        "colab_type": "code",
        "outputId": "34c14245-d485-4706-b970-e9881cd54ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "\n",
        "train_loader = dataloaders['train']\n",
        "test_loader = dataloaders['val']\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01,  momentum=0.9)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=0.03,  total_steps=50,pct_start=0.3, final_div_factor=1, div_factor=10)\n",
        "lrs=[]\n",
        "\n",
        "for epoch in range(1, 50):\n",
        "    curr_lr=optimizer.param_groups[0]['lr']\n",
        "    lrs.append(curr_lr)\n",
        "    print(f'Epoch: {epoch} Learning_Rate {curr_lr}')\n",
        "    train_acc1 = train(model, device, train_loader, optimizer, epoch)\n",
        "    test_acc1 = test(model, device, test_loader)\n",
        "    print('Test acc:', test_acc1)\n",
        "    scheduler.step()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Learning_Rate 0.002999999999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-29.766357421875 Batch_id=150 Accuracy=0.65: 100%|██████████| 151/151 [02:46<00:00,  1.10s/it]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: -31.2994, Accuracy: 0/33000 (0.00%)\n",
            "\n",
            "Test acc: 0.0\n",
            "Epoch: 2 Learning_Rate 0.0033384731855453827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-201.3048095703125 Batch_id=150 Accuracy=1.10: 100%|██████████| 151/151 [02:45<00:00,  1.09s/it]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: -187.9816, Accuracy: 0/33000 (0.00%)\n",
            "\n",
            "Test acc: 0.0\n",
            "Epoch: 3 Learning_Rate 0.004336920283317343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-1681.71337890625 Batch_id=150 Accuracy=0.94: 100%|██████████| 151/151 [02:43<00:00,  1.08s/it]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: -1420.3485, Accuracy: 0/33000 (0.00%)\n",
            "\n",
            "Test acc: 0.0\n",
            "Epoch: 4 Learning_Rate 0.0059452749866815945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-30797.21484375 Batch_id=150 Accuracy=0.83: 100%|██████████| 151/151 [02:41<00:00,  1.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7dd9899d886a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch} Learning_Rate {curr_lr}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_acc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtest_acc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils/train_test.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, criterion)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# get samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0;31m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0;31m# workers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers_status\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m                     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_shutdown_worker\u001b[0;34m(self, worker_id)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# Indicate that no more data will be put on this queue by the current\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;31m# process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;31m# Note that we don't actually join the worker here, nor do we remove the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, obj, block, timeout)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHRGz_G1RZdz",
        "colab_type": "code",
        "outputId": "50db3792-076e-4ef1-c99d-6be71baf7199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001,  momentum=0.9)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=0.03,  total_steps=50,pct_start=0.3, final_div_factor=1, div_factor=10)\n",
        "save_path = '/content/gdrive/My Drive/Colab Notebooks/eva4_s12/'\n",
        "train_model(save_path,model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "\r  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-35.214149475097656 Batch_id=150 : 100%|██████████| 151/151 [02:47<00:00,  1.11s/it]\n",
            "Loss=-38.40053939819336 Batch_id=64 : 100%|██████████| 65/65 [00:33<00:00,  1.96it/s]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: -11.1578 Acc: 0.0101\n",
            "Val Loss: -38.4898 Acc: 0.0000\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-293.37115478515625 Batch_id=150 : 100%|██████████| 151/151 [02:44<00:00,  1.09s/it]\n",
            "Loss=-350.1878662109375 Batch_id=64 : 100%|██████████| 65/65 [00:33<00:00,  1.96it/s]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: -128.5696 Acc: 0.0131\n",
            "Val Loss: -353.9236 Acc: 0.0000\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-4597.02197265625 Batch_id=150 : 100%|██████████| 151/151 [02:45<00:00,  1.10s/it]\n",
            "Loss=-5424.5341796875 Batch_id=64 : 100%|██████████| 65/65 [00:33<00:00,  1.95it/s]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: -1524.8648 Acc: 0.0133\n",
            "Val Loss: -5588.0035 Acc: 0.0000\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-157992.203125 Batch_id=150 : 100%|██████████| 151/151 [02:43<00:00,  1.08s/it]\n",
            "Loss=-165629.0625 Batch_id=64 : 100%|██████████| 65/65 [00:33<00:00,  1.96it/s]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: -43091.1595 Acc: 0.0112\n",
            "Val Loss: -166963.8848 Acc: 0.0000\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-11275680.0 Batch_id=150 : 100%|██████████| 151/151 [02:44<00:00,  1.09s/it]\n",
            "Loss=-8660867.0 Batch_id=64 : 100%|██████████| 65/65 [00:33<00:00,  1.96it/s]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: -2621269.2963 Acc: 0.0074\n",
            "Val Loss: -8614144.5176 Acc: 0.0000\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-671684096.0 Batch_id=127 :  85%|████████▍ | 128/151 [02:21<00:20,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-21a9eef9437e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneCycleLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtotal_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpct_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_div_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/eva4_s12/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/utils/train_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(output_path, model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs, scheduler)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                                 \u001b[0;31m#print(\"\\rIteration: {}/{}, Loss: {}.\".format(i+1, len(dataloaders[phase]), loss.item() * inputs.size(0)), end=\"\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ywfxfg3FMuK",
        "colab_type": "code",
        "outputId": "c9b87554-3cf2-42ad-f902-852a0ad0390f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "PATH = '/content/gdrive/My Drive/Colab Notebooks/eva4_s9/assignment11_ResNetcust_model.h5'\n",
        "!touch PATH\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}