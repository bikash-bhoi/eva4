{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session_12_TinyImgNet_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bikash-bhoi/eva4/blob/master/Session12/Session_12_TinyImgNet_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwcC29-mHU7H",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g7ee78QSLcf",
        "colab_type": "code",
        "outputId": "b92ec756-cdfa-4416-f7f3-ea1595ec0a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##Clone Github Directory to import packages\n",
        "%%bash\n",
        "mkdir temp\n",
        "git clone https://github.com/bikash-bhoi/eva4.git temp\n",
        "if [ ! -d ./models ]; then\n",
        "    mkdir models\n",
        "fi\n",
        "if [ ! -d ./utils ]; then\n",
        "    mkdir utils\n",
        "fi\n",
        "cp -r temp/models/* ./models\n",
        "cp -r temp/utils/* ./utils\n",
        "rm -rf temp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'temp'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5jmWLvznBDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install pytorch-gradcam\n",
        "!pip install albumentations\n",
        "!pip install livelossplot\n",
        "#!pip install --no-cache-dir git+https://github.com/NVIDIA/apex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAMhoRfM-4nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from utils.download_load import download_load\n",
        "#from utils.display_imgs import display_imgs\n",
        "from utils.train_test import train , test, predict, get_misclassified\n",
        "from utils.disp_summary import disp_summary\n",
        "#from utils.gradcam import grad_cam, gradcam_plot\n",
        "from models.resnet import ResNet18,ResNet\n",
        "from utils.range_test import lr_range_test\n",
        "from utils.train_model import train_model\n",
        "#from utils.zig_zag_plot import zigzag_plot\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchsummary\n",
        "from torchsummary import summary\n",
        "import torch,os\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "from skimage import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj2uhhjFKcM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/tiny-imagenet-200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI_r1Qto8Tc_",
        "colab_type": "code",
        "outputId": "ab710b18-08e4-41f7-9d10-d7be1201fc7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "#!rm -rf /content/tiny-imagenet-200\n",
        "!unzip -q \"/content/gdrive/My Drive/tiny-imagenet-200.zip\"\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F5_WAaIQ05S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data_dir = '/content/tiny-imagenet-200/'\n",
        "classes = [line.strip() for line in open( data_dir + 'wnids.txt', 'r')]\n",
        "class_dict = {x:i for i, x in enumerate(classes)}\n",
        "all_c = {line.split('\\t')[0] : line.split('\\t')[1].strip() for line in open( data_dir + 'words.txt', 'r')}\n",
        "class_names = [all_c[x] for x in classes]\n",
        "\n",
        "imgs = []\n",
        "lbls = []\n",
        "\n",
        "for v, c in enumerate(classes):\n",
        "\timgs += [f'{data_dir}train/{c}/images/{c}_{i}.JPEG' for i in range(500)]\n",
        "\tlbls += [v for i in range(500)]\n",
        "\n",
        "for line in open( data_dir + 'val/val_annotations.txt'):\n",
        "\timg_name, class_id = line.split('\\t')[:2]\n",
        "\timgs.append(f'{data_dir}val/images/{img_name}')\n",
        "\tlbls.append(class_dict[class_id])\n",
        "\n",
        "dataset = list(zip(imgs, lbls))\n",
        "random.shuffle(dataset)\n",
        "\n",
        "\n",
        "class TinyImagenetReadData(Dataset):\n",
        "\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.transform = transform\n",
        "        self.images, self.labels = zip(*data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        image = io.imread(self.images[idx], as_gray=False, pilmode=\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.labels[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "San8jCXJ5V8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import albumentations\n",
        "from albumentations import *\n",
        "from albumentations import Compose\n",
        "from albumentations.pytorch import ToTensor\n",
        "import numpy as np\n",
        "\n",
        "means = (0.48043839, 0.44820218, 0.39760034)\n",
        "stds = (0.27698959, 0.26908774, 0.28216029)\n",
        "class TrainAlbumentation():\n",
        "\tdef __init__(self):\n",
        "\t\tself.train_trans = Compose([\n",
        "\t\t\t\t\t\t\tA.PadIfNeeded(min_height=80, min_width=80, border_mode=cv2.BORDER_CONSTANT, value=np.array(means)*255),\n",
        "\t\t\t\t\t\t\tA.RandomCrop(64,64, always_apply=True),\n",
        "\t\t\t\t\t\t\tA.Rotate((-25.0, 25.0)),\n",
        "\t\t\t\t\t\t\tA.HorizontalFlip(),\n",
        "\t\t\t\t\t\t\tA.RGBShift(r_shift_limit=40, g_shift_limit=40, b_shift_limit=40, p=0.5),\n",
        "\t\t\t\t\t\t\tA.Normalize(mean=means, std=stds),\n",
        "\t\t\t\t\t\t\tA.Cutout(num_holes=4, max_h_size=24, max_w_size=24) ,\n",
        "\t\t\t\t\t\t\tToTensor()\n",
        "\t\t\t\t\t\t\t])\n",
        "\n",
        "\tdef __call__(self, im):\n",
        "\t\tim = np.array(im)\n",
        "\t\tim = self.train_trans(image = im)['image']\n",
        "\t\treturn im\n",
        " \n",
        "class TestAlbumentation():\n",
        "\tdef __init__(self):\n",
        "\t\tself.train_trans = Compose([A.Normalize(mean=means, std=stds)], ToTensor())\n",
        "\n",
        "\tdef __call__(self, im):\n",
        "\t\tim = np.array(im)\n",
        "\t\tim = self.train_trans(image = im)['image']\n",
        "\t\treturn im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soN156J5FBoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RoQ8SKq8aTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba42836b-8b90-4de4-a548-8d54a3e100b5"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchsummary\n",
        "from torchsummary import summary\n",
        "from utils.data_albument import TrainAlbumentation,TestAlbumentation\n",
        "\n",
        "\n",
        "train_bs = 512\n",
        "test_bs = 512\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "SEED=1\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "transform_train = TrainAlbumentation()\n",
        "transform_test = TestAlbumentation()\n",
        "#transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "#transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "#trainoader_args = dict(shuffle=True, batch_size=train_bs, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "#testloader_args = dict(shuffle=False, batch_size=test_bs, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "trainlen = int(len(dataset)*0.7)\n",
        "train = TinyImagenetReadData(dataset[:trainlen], transform=transform_train)\n",
        "test = TinyImagenetReadData(dataset[trainlen:], transform=transform_test)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EoNkPUKYE9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eawy86MA3hU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e7c96bd-c8f1-46c5-92c7-32ff2ae67911"
      },
      "source": [
        "train"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.TinyImagenetReadData at 0x7fd990090080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVkm5gyA5mvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Do not use\n",
        "import torch\n",
        "\n",
        "class DataLoader:\n",
        "  def __init__(self, shuffle=True, batch_size=128, seed=1):\n",
        "    cuda = torch.cuda.is_available()\n",
        "    \n",
        "    if cuda:\n",
        "      torch.cuda.manual_seed(seed)\n",
        "\n",
        "    self.dataloader_args = dict(shuffle=shuffle, batch_size=batch_size, num_workers=1, pin_memory=True) if cuda else dict(shuffle=shuffle, batch_size=batch_size)\n",
        "\n",
        "  def load(self, data):\n",
        "    return torch.utils.data.DataLoader(data, **self.dataloader_args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p08f94aNJMXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader = DataLoader(batch_size=512, shuffle=True)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = dataloader.load(train)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = dataloader.load(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fPLqDXsYpse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5378c981-f1b8-46e7-f8d1-80f26d6a160c"
      },
      "source": [
        "next(iter(train_loader))[0].shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 3, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ays4k29NzQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import torchvision.models as models\n",
        "#model = models.resnet18()\n",
        "#Finetune Final few layers to adjust for tiny imagenet input\n",
        "#model.conv1 = nn.Conv2d(3,64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False)\n",
        "#model.maxpool = nn.Sequential()\n",
        "#model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "#model.fc.out_features = 200\n",
        "\n",
        "model=ResNet18(200)\n",
        "#model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "use_cuda= torch.cuda.is_available()\n",
        "device=torch.device('cuda' if use_cuda else 'cpu')\n",
        "model=model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f6-gJxyOM7t",
        "colab_type": "code",
        "outputId": "7ac4051b-2bc9-4a6b-b432-b6be056a16f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "disp_summary(model,[3,64,64])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 64, 64]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
            "         Dropout2d-3           [-1, 64, 64, 64]               0\n",
            "            Conv2d-4           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-5           [-1, 64, 64, 64]             128\n",
            "         Dropout2d-6           [-1, 64, 64, 64]               0\n",
            "            Conv2d-7           [-1, 64, 64, 64]          36,864\n",
            "       BatchNorm2d-8           [-1, 64, 64, 64]             128\n",
            "         Dropout2d-9           [-1, 64, 64, 64]               0\n",
            "       BasicBlock-10           [-1, 64, 64, 64]               0\n",
            "           Conv2d-11           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-12           [-1, 64, 64, 64]             128\n",
            "        Dropout2d-13           [-1, 64, 64, 64]               0\n",
            "           Conv2d-14           [-1, 64, 64, 64]          36,864\n",
            "      BatchNorm2d-15           [-1, 64, 64, 64]             128\n",
            "        Dropout2d-16           [-1, 64, 64, 64]               0\n",
            "       BasicBlock-17           [-1, 64, 64, 64]               0\n",
            "        Dropout2d-18           [-1, 64, 64, 64]               0\n",
            "           Conv2d-19          [-1, 128, 32, 32]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 32, 32]             256\n",
            "        Dropout2d-21          [-1, 128, 32, 32]               0\n",
            "           Conv2d-22          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 32, 32]             256\n",
            "        Dropout2d-24          [-1, 128, 32, 32]               0\n",
            "           Conv2d-25          [-1, 128, 32, 32]           8,192\n",
            "      BatchNorm2d-26          [-1, 128, 32, 32]             256\n",
            "       BasicBlock-27          [-1, 128, 32, 32]               0\n",
            "           Conv2d-28          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 32, 32]             256\n",
            "        Dropout2d-30          [-1, 128, 32, 32]               0\n",
            "           Conv2d-31          [-1, 128, 32, 32]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 32, 32]             256\n",
            "        Dropout2d-33          [-1, 128, 32, 32]               0\n",
            "       BasicBlock-34          [-1, 128, 32, 32]               0\n",
            "        Dropout2d-35          [-1, 128, 32, 32]               0\n",
            "           Conv2d-36          [-1, 256, 16, 16]         294,912\n",
            "      BatchNorm2d-37          [-1, 256, 16, 16]             512\n",
            "        Dropout2d-38          [-1, 256, 16, 16]               0\n",
            "           Conv2d-39          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-40          [-1, 256, 16, 16]             512\n",
            "        Dropout2d-41          [-1, 256, 16, 16]               0\n",
            "           Conv2d-42          [-1, 256, 16, 16]          32,768\n",
            "      BatchNorm2d-43          [-1, 256, 16, 16]             512\n",
            "       BasicBlock-44          [-1, 256, 16, 16]               0\n",
            "           Conv2d-45          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-46          [-1, 256, 16, 16]             512\n",
            "        Dropout2d-47          [-1, 256, 16, 16]               0\n",
            "           Conv2d-48          [-1, 256, 16, 16]         589,824\n",
            "      BatchNorm2d-49          [-1, 256, 16, 16]             512\n",
            "        Dropout2d-50          [-1, 256, 16, 16]               0\n",
            "       BasicBlock-51          [-1, 256, 16, 16]               0\n",
            "        Dropout2d-52          [-1, 256, 16, 16]               0\n",
            "           Conv2d-53            [-1, 512, 8, 8]       1,179,648\n",
            "      BatchNorm2d-54            [-1, 512, 8, 8]           1,024\n",
            "        Dropout2d-55            [-1, 512, 8, 8]               0\n",
            "           Conv2d-56            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
            "        Dropout2d-58            [-1, 512, 8, 8]               0\n",
            "           Conv2d-59            [-1, 512, 8, 8]         131,072\n",
            "      BatchNorm2d-60            [-1, 512, 8, 8]           1,024\n",
            "       BasicBlock-61            [-1, 512, 8, 8]               0\n",
            "           Conv2d-62            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-63            [-1, 512, 8, 8]           1,024\n",
            "        Dropout2d-64            [-1, 512, 8, 8]               0\n",
            "           Conv2d-65            [-1, 512, 8, 8]       2,359,296\n",
            "      BatchNorm2d-66            [-1, 512, 8, 8]           1,024\n",
            "        Dropout2d-67            [-1, 512, 8, 8]               0\n",
            "       BasicBlock-68            [-1, 512, 8, 8]               0\n",
            "        Dropout2d-69            [-1, 512, 8, 8]               0\n",
            "           Linear-70                  [-1, 200]         102,600\n",
            "================================================================\n",
            "Total params: 11,271,432\n",
            "Trainable params: 11,271,432\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 65.75\n",
            "Params size (MB): 43.00\n",
            "Estimated Total Size (MB): 108.80\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/models/resnet.py:97: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(out)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CZTHNLGLGh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrs = [j*(10**i) for i in range(-3,-1) for j in range(1,11)]\n",
        "lr_range_test(lrs,model,device,train_loader, test_loader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ7c7UTxOPJn",
        "colab_type": "code",
        "outputId": "e9c22959-36c4-4de0-dd8c-f5174c51c297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01,  momentum=0.9)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=0.03,  total_steps=50,pct_start=0.3, final_div_factor=1, div_factor=10)\n",
        "lrs=[]\n",
        "\n",
        "for epoch in range(1, 50):\n",
        "    curr_lr=optimizer.param_groups[0]['lr']\n",
        "    lrs.append(curr_lr)\n",
        "    print(f'Epoch: {epoch} Learning_Rate {curr_lr}')\n",
        "    train_acc1 = train(model, device, train_loader, optimizer, epoch)\n",
        "    test_acc1 = test(model, device, test_loader)\n",
        "    print('Test acc:', test_acc1)\n",
        "    scheduler.step()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Learning_Rate 0.002999999999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-73a8b8278398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch} Learning_Rate {curr_lr}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_acc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtest_acc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'TinyImagenetReadData' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHRGz_G1RZdz",
        "colab_type": "code",
        "outputId": "50db3792-076e-4ef1-c99d-6be71baf7199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001,  momentum=0.9)\n",
        "scheduler = OneCycleLR(optimizer, max_lr=0.03,  total_steps=50,pct_start=0.3, final_div_factor=1, div_factor=10)\n",
        "save_path = '/content/gdrive/My Drive/Colab Notebooks/eva4_s12/'\n",
        "train_model(save_path,model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs=50, scheduler=scheduler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "\r  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-35.214149475097656 Batch_id=150 : 100%|██████████| 151/151 [02:47<00:00,  1.11s/it]\n",
            "Loss=-38.40053939819336 Batch_id=64 : 100%|██████████| 65/65 [00:33<00:00,  1.96it/s]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: -11.1578 Acc: 0.0101\n",
            "Val Loss: -38.4898 Acc: 0.0000\n",
            "\n",
            "Epoch 2/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-293.37115478515625 Batch_id=150 : 100%|██████████| 151/151 [02:44<00:00,  1.09s/it]\n",
            "Loss=-350.1878662109375 Batch_id=64 : 100%|██████████| 65/65 [00:33<00:00,  1.96it/s]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: -128.5696 Acc: 0.0131\n",
            "Val Loss: -353.9236 Acc: 0.0000\n",
            "\n",
            "Epoch 3/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-4597.02197265625 Batch_id=150 : 100%|██████████| 151/151 [02:45<00:00,  1.10s/it]\n",
            "Loss=-5424.5341796875 Batch_id=64 : 100%|██████████| 65/65 [00:33<00:00,  1.95it/s]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: -1524.8648 Acc: 0.0133\n",
            "Val Loss: -5588.0035 Acc: 0.0000\n",
            "\n",
            "Epoch 4/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-157992.203125 Batch_id=150 : 100%|██████████| 151/151 [02:43<00:00,  1.08s/it]\n",
            "Loss=-165629.0625 Batch_id=64 : 100%|██████████| 65/65 [00:33<00:00,  1.96it/s]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: -43091.1595 Acc: 0.0112\n",
            "Val Loss: -166963.8848 Acc: 0.0000\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-11275680.0 Batch_id=150 : 100%|██████████| 151/151 [02:44<00:00,  1.09s/it]\n",
            "Loss=-8660867.0 Batch_id=64 : 100%|██████████| 65/65 [00:33<00:00,  1.96it/s]\n",
            "  0%|          | 0/151 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Loss: -2621269.2963 Acc: 0.0074\n",
            "Val Loss: -8614144.5176 Acc: 0.0000\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=-671684096.0 Batch_id=127 :  85%|████████▍ | 128/151 [02:21<00:20,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-21a9eef9437e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneCycleLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtotal_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpct_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_div_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/Colab Notebooks/eva4_s12/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/utils/train_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(output_path, model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs, scheduler)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                                 \u001b[0;31m#print(\"\\rIteration: {}/{}, Loss: {}.\".format(i+1, len(dataloaders[phase]), loss.item() * inputs.size(0)), end=\"\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ywfxfg3FMuK",
        "colab_type": "code",
        "outputId": "c9b87554-3cf2-42ad-f902-852a0ad0390f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "PATH = '/content/gdrive/My Drive/Colab Notebooks/eva4_s9/assignment11_ResNetcust_model.h5'\n",
        "!touch PATH\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}